#!/usr/bin/env python3
# logwatch_tui.py  -- live TUI for fingerprints/logs
# Run as root for best access: sudo python3 /root/logwatch_tui.py

import curses, time, subprocess, shlex, os, csv
from collections import Counter, deque, defaultdict
from datetime import datetime

# Config
SCAN_LINES = 2000            # how many lines to scan from each source per refresh
REFRESH_SEC = 3              # default refresh interval
OUTDIR = "/root/homelab-fingerprints"
os.makedirs(OUTDIR, exist_ok=True)

# Sources to scan (adjust as needed)
NGINX_LOGS = ["/var/log/nginx/access.log", "/var/log/nginx/access.log.1"]
AUTH_LOG = "/var/log/auth.log"
JOURNAL_SINCE = "1m"  # last 1 minute of journalctl (fallback)
DOCKER_CONTAINERS = True  # try to query docker logs if docker exists
DOCKER_LINES = 500

# Basic helpers
def sh(cmd):
    try:
        out = subprocess.check_output(shlex.split(cmd), stderr=subprocess.DEVNULL, timeout=6)
        return out.decode('utf-8', errors='ignore')
    except Exception:
        return ""

def tail_file(path, n):
    if not os.path.exists(path):
        return []
    try:
        out = sh(f"tail -n {n} {path}")
        return out.splitlines()
    except Exception:
        return []

def journal_recent(since="1m"):
    return sh(f"journalctl --since \"{since}\" -o short-iso -n {SCAN_LINES}")

def docker_recent_lines():
    lines = []
    if not shutil_which("docker"):
        return lines
    # list containers
    out = sh("docker ps --format '{{.Names}}'")
    for cname in out.splitlines():
        if not cname.strip():
            continue
        # read recent logs
        l = sh(f"docker logs --since 1m --timestamps {cname} 2>/dev/null")
        if l:
            for L in l.splitlines():
                lines.append(f"docker[{cname}]: {L}")
    return lines

def shutil_which(name):
    return subprocess.call(["which", name], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) == 0

# parsers (simple, heuristic)
import re
IP_RE = re.compile(r'(?:(?:\d{1,3}\.){3}\d{1,3})')
UA_RE = re.compile(r'User-Agent[:=] ?(.+)$', re.I)
REQ_RE = re.compile(r'\"(GET|POST|PUT|DELETE|PATCH) ([^ ]+)')

def parse_lines(lines, counters):
    recent = deque(maxlen=200)
    for line in lines:
        if not line:
            continue
        # timestamp optionally
        ts = ""
        m = re.search(r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}', line)
        if m:
            ts = m.group(0)
        ip = ""
        ipm = IP_RE.search(line)
        if ipm:
            ip = ipm.group(0)
            counters['ips'][ip] += 1
        ua = ""
        uam = UA_RE.search(line)
        if uam:
            ua = uam.group(1).strip()
            counters['uas'][ua] += 1
        reqm = REQ_RE.search(line)
        if reqm:
            path = reqm.group(2)
            counters['uris'][path] += 1
        # store recent suspicious-looking lines (auth failures, password, failed, POST login, CF-Connecting-IP)
        if re.search(r'(?i)fail|failed|unauthori|password|CF-Connecting-IP|X-Forwarded-For|POST .*login|POST .*auth', line):
            recent.appendleft((ts or datetime.utcnow().isoformat(), ip, line.strip()))
    return recent

def gather_all():
    counters = {'ips': Counter(), 'uas': Counter(), 'uris': Counter()}
    recent_lines = deque(maxlen=400)
    # 1) nginx logs
    for f in NGINX_LOGS:
        for ln in tail_file(f, SCAN_LINES):
            r = parse_lines([ln], counters)
            recent_lines.extendleft(r)
    # 2) auth log
    for ln in tail_file(AUTH_LOG, SCAN_LINES):
        r = parse_lines([ln], counters)
        recent_lines.extendleft(r)
    # 3) journal
    j = journal_recent(JOURNAL_SINCE)
    for ln in j.splitlines():
        r = parse_lines([ln], counters)
        recent_lines.extendleft(r)
    # 4) docker (best-effort, short)
    if shutil_which("docker"):
        out = sh(f"docker ps --format '{{{{.Names}}}}'")
        for cname in out.splitlines():
            if not cname: continue
            lns = sh(f"docker logs --since 1m --timestamps {cname} 2>/dev/null").splitlines()
            for ln in lns[-200:]:
                r = parse_lines([f"docker[{cname}]: {ln}"], counters)
                recent_lines.extendleft(r)
    return counters, list(recent_lines)[:200]

# TUI
def draw(scr):
    curses.use_default_colors()
    scr.nodelay(True)
    last = 0
    snapshot_count = 0
    global REFRESH_SEC
    while True:
        now = time.time()
        if now - last >= REFRESH_SEC:
            counters, recent = gather_all()
            last = now
        scr.erase()
        h, w = scr.getmaxyx()
        # Header
        scr.addstr(0,0, "logwatch â€” live fingerprint dashboard    (r refresh | s save snapshot | q quit)")
        scr.addstr(1,0, f"refresh every {REFRESH_SEC}s | scanned top lines: {SCAN_LINES} | last: {datetime.utcnow().isoformat()}")

        # Left column: top IPs
        scr.addstr(3,0, "Top Source IPs")
        ips = counters['ips'].most_common(12)
        for i,(ip,c) in enumerate(ips):
            scr.addstr(4+i, 0, f"{i+1:2d}. {ip:16s} {c:6d}")

        # Middle column: top UAs
        midx = 40
        scr.addstr(3,midx, "Top User-Agents")
        uas = counters['uas'].most_common(8)
        for i,(ua,c) in enumerate(uas):
            ua_short = (ua[:w-midx-20] + '...') if len(ua) > (w-midx-20) else ua
            scr.addstr(4+i, midx, f"{i+1:2d}. {ua_short: <{w-midx-20}} {c:4d}")

        # Right column: top URIs
        rcol = 110 if w>130 else (midx+40)
        scr.addstr(3,rcol, "Top Endpoints")
        uris = counters['uris'].most_common(8)
        for i,(u,c) in enumerate(uris):
            u_short = (u[:w-rcol-20] + '...') if len(u) > (w-rcol-20) else u
            scr.addstr(4+i, rcol, f"{i+1:2d}. {u_short: <{w-rcol-20}} {c:4d}")

        # Recent suspicious lines (bottom)
        bottom_start = 14
        scr.addstr(bottom_start-1,0, "Recent suspicious lines (most recent first):")
        for idx, (ts, ip, line) in enumerate(recent[:min(10, len(recent))]):
            ln = f"{ts} {ip:15s} {line}"
            ln = (ln[:w-1]) if len(ln) >= w else ln
            scr.addstr(bottom_start+idx, 0, ln)

        # Input handling
        try:
            ch = scr.getch()
            if ch == ord('q'):
                return
            elif ch == ord('r'):
                last = 0  # force refresh
            elif ch == ord('s'):
                # save snapshot CSV
                snapshot_count += 1
                fname = os.path.join(OUTDIR, f"snapshot_{datetime.utcnow().strftime('%F_%H%M%S')}.csv")
                with open(fname, "w", newline='', encoding='utf-8') as fh:
                    writer = csv.writer(fh)
                    writer.writerow(["rank","type","value","count"])
                    for i,(v,c) in enumerate(counters['ips'].most_common(100),1):
                        writer.writerow([i,"ip",v,c])
                    for i,(v,c) in enumerate(counters['uas'].most_common(100),1):
                        writer.writerow([i,"ua",v,c])
                    for i,(v,c) in enumerate(counters['uris'].most_common(100),1):
                        writer.writerow([i,"uri",v,c])
                scr.addstr(h-2,0, f"Saved snapshot: {fname}")
        except curses.error:
            pass

        scr.refresh()
        time.sleep(0.1)

def main():
    curses.wrapper(draw)

if __name__ == "__main__":
    main()
